{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAKESPEARE RESEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For an exhaustive research on Shakespeare's literary works, we need to know how many times the author uses every word in three of his masterpieces: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. King Lear:  \n",
    "  * https://storage.cloud.google.com/apache-beam-samples/shakespeare/kinglear.txt   \n",
    " \n",
    "2. Othello: \n",
    "  * https://storage.cloud.google.com/apache-beam-samples/shakespeare/othello.txt   \n",
    " \n",
    "3. Romeo and Juliet: \n",
    "  * https://storage.cloud.google.com/apache-beam-samples/shakespeare/romeoandjuliet.txt \n",
    " \n",
    " \n",
    "The expected output should be a single file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(txt) :\n",
    "    f = open(txt,\"r\")\n",
    "    raw = f.read()\n",
    "    tokens = nltk.word_tokenize(raw)\n",
    "    words = [w.lower for w in tokens]\n",
    "    vocab = sorted(set(tokens))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequencies(txt, include_punct=False):\n",
    "    fdist = FreqDist()\n",
    "    f = open(txt,\"r\")\n",
    "    raw = f.read()\n",
    "    for sent in nltk.tokenize.sent_tokenize(raw): #first tokenize sentences\n",
    "        for word in nltk.tokenize.word_tokenize(sent): #then tokenize words for each sentence\n",
    "            if include_punct==False:\n",
    "                if word not in punctuations:\n",
    "                    fdist[word] += 1\n",
    "            else:\n",
    "                fdist[word] += 1\n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_append(txt):\n",
    "    with open(\"shakespeare_word_count.txt\", \"a\") as output_file:\n",
    "        output_file.write(\"%s\\n\"%f.upper())\n",
    "        freqs = get_frequencies(f)\n",
    "        for (k,v) in freqs.items():\n",
    "            output_file.write(\"%s:%s\\n\"%(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output to a single file named 'shakespeare_word_count.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['shakespeare_kinglear.txt', 'shakespeare_othello.txt', 'shakespeare_romeoandjuliet.txt']:\n",
    "    write_append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show top 10 most frequent words for each masterpiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAKESPEARE_KINGLEAR.TXT\n",
      "the:\t786\n",
      "I:\t697\n",
      "and:\t593\n",
      "of:\t447\n",
      "to:\t429\n",
      "you:\t404\n",
      "my:\t402\n",
      "a:\t355\n",
      "not:\t287\n",
      "in:\t270\n",
      "\n",
      "\n",
      "SHAKESPEARE_OTHELLO.TXT\n",
      "I:\t884\n",
      "the:\t674\n",
      "and:\t596\n",
      "to:\t477\n",
      "you:\t452\n",
      "of:\t420\n",
      "a:\t394\n",
      "my:\t368\n",
      "not:\t331\n",
      "is:\t316\n",
      "\n",
      "\n",
      "SHAKESPEARE_ROMEOANDJULIET.TXT\n",
      "I:\t648\n",
      "the:\t614\n",
      "and:\t490\n",
      "to:\t456\n",
      "a:\t404\n",
      "of:\t367\n",
      "is:\t334\n",
      "my:\t314\n",
      "in:\t290\n",
      "'s:\t284\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in ['shakespeare_kinglear.txt', 'shakespeare_othello.txt', 'shakespeare_romeoandjuliet.txt']:\n",
    "    print(\"%s\"%f.upper())\n",
    "    freqs = get_frequencies(f)\n",
    "    for wf in freqs.most_common(10):\n",
    "        print(\"%s:\\t%s\"%(wf[0],wf[1]))\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
